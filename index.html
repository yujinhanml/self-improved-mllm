<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <!-- TODO: Replace with your paper title and author names -->
  <meta name="title" content="PAPER_TITLE - AUTHOR_NAMES">
  <!-- TODO: Write a compelling 150-160 character description of your research -->
  <meta name="description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Add 5-10 relevant keywords for your research area -->
  <meta name="keywords" content="KEYWORD1, KEYWORD2, KEYWORD3, machine learning, computer vision, AI">
  <!-- TODO: List all authors -->
  <meta name="author" content="FIRST_AUTHOR_NAME, SECOND_AUTHOR_NAME">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <!-- TODO: Replace with your institution or lab name -->
  <meta property="og:site_name" content="INSTITUTION_OR_LAB_NAME">
  <!-- TODO: Same as paper title above -->
  <meta property="og:title" content="PAPER_TITLE">
  <!-- TODO: Same as description above -->
  <meta property="og:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Replace with your actual website URL -->
  <meta property="og:url" content="https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE">
  <!-- TODO: Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="PAPER_TITLE - Research Preview">
  <meta property="article:published_time" content="2024-01-01T00:00:00.000Z">
  <meta property="article:author" content="FIRST_AUTHOR_NAME">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="KEYWORD1">
  <meta property="article:tag" content="KEYWORD2">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <!-- TODO: Replace with your lab/institution Twitter handle -->
  <meta name="twitter:site" content="@YOUR_TWITTER_HANDLE">
  <!-- TODO: Replace with first author's Twitter handle -->
  <meta name="twitter:creator" content="@AUTHOR_TWITTER_HANDLE">
  <!-- TODO: Same as paper title above -->
  <meta name="twitter:title" content="PAPER_TITLE">
  <!-- TODO: Same as description above -->
  <meta name="twitter:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Same as social preview image above -->
  <meta name="twitter:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="PAPER_TITLE - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="PAPER_TITLE">
  <meta name="citation_author" content="FIRST_AUTHOR_LAST, FIRST_AUTHOR_FIRST">
  <meta name="citation_author" content="SECOND_AUTHOR_LAST, SECOND_AUTHOR_FIRST">
  <meta name="citation_publication_date" content="2024">
  <meta name="citation_conference_title" content="CONFERENCE_NAME">
  <meta name="citation_pdf_url" content="https://YOUR_DOMAIN.com/static/pdfs/paper.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <!-- TODO: Replace with your paper title and authors -->
  <title>PAPER_TITLE - AUTHOR_NAMES | Academic Research</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "PAPER_TITLE",
    "description": "BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS",
    "author": [
      {
        "@type": "Person",
        "name": "FIRST_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      },
      {
        "@type": "Person",
        "name": "SECOND_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      }
    ],
    "datePublished": "2024-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "CONFERENCE_OR_JOURNAL_NAME"
    },
    "url": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["KEYWORD1", "KEYWORD2", "KEYWORD3", "machine learning", "computer vision"],
    "abstract": "FULL_ABSTRACT_TEXT_HERE",
    "citation": "BIBTEX_CITATION_HERE",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "RESEARCH_AREA_1"
      },
      {
        "@type": "Thing", 
        "name": "RESEARCH_AREA_2"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "INSTITUTION_OR_LAB_NAME",
    "url": "https://YOUR_INSTITUTION_WEBSITE.com",
    "logo": "https://YOUR_DOMAIN.com/static/images/favicon.ico",
    "sameAs": [
      "https://twitter.com/YOUR_TWITTER_HANDLE",
      "https://github.com/YOUR_GITHUB_USERNAME"
    ]
  }
  </script>

  <!-- MathJax v3：行内公式 \(...\) / $...$，并加载 \text{} 所需扩展 -->
  <script>
    window.MathJax = {
      loader: { load: ['[tex]/textmacros'] },      // 真的去加载 textmacros 扩展
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],  // 行内公式分隔符
        packages: {'[+]': ['textmacros']}         // 让 TeX 输入机认识 \text{}
      },
      svg: { fontCache: 'global' }
    };
  </script>
  <script id="MathJax-script" defer
          src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>


  <script>
  $(document).ready(function() {
    // 初始化轮播图
    bulmaCarousel.attach('#results-carousel-1', {
      slidesToScroll: 1,
      slidesToShow: 1,
      infinite: false
    });
    
    // 获取轮播图实例
    const carousel = bulmaCarousel.attach('#results-carousel-1')[0];
    
    // 标题更新函数
    function updateTitle() {
      const activeSlide = $('.carousel-item.is-active .item');
      const newTitle = activeSlide.data('title');
      $('#carousel-title-1').text(newTitle);
    }
    
    // 初始加载时更新标题
    updateTitle();
    
    // 监听轮播图切换事件
    carousel.on('after:show', updateTitle);
    
    // 兼容性处理：监听分页按钮点击
    $('.carousel-pagination li').on('click', function() {
      setTimeout(updateTitle, 100); // 等待动画完成
    });
  });
  </script>

</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <!-- TODO: Replace with your paper title -->
            <h1 class="title is-1 publication-title">Turning Internal Gap into Self-Improvement: Promoting the Generation-Understanding Unification in MLLMs</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://yujinhanml.github.io" target="_blank">Yujin Han</a><sup>1,8</sup>,
              </span>
              <span class="author-block">
                <a href="https://hhhhhhao.github.io/" target="_blank">Hao Chen</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://andihan3.github.io/" target="_blank">Andi Han</a><sup>3,4</sup>,
              </span>
              <span class="author-block">
                <a href="https://w-zhih.github.io/" target="_blank">Zhiheng Wang</a><sup>5,6</sup>,
              </span>
              <span class="author-block">
                <a href="https://liuxinyv.github.io/" target="_blank">Xinyu Liu</a><sup>7</sup>,
              </span>
              <span class="author-block">
                <a href="https://openreview.net/profile?id=~Yingya_Zhang3" target="_blank">Yingya Zhang</a><sup>8</sup>,
              </span>
              <span class="author-block">
                <a href="https://openreview.net/profile?id=~Shiwei_Zhang2" target="_blank">Shiwei Zhang</a><sup>8,†</sup>,
              </span>
              <span class="author-block">
                <a href="https://difanzou.github.io/" target="_blank">Difan Zou</a><sup>1,†</sup>
              </span>
            </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">
                      <sup>1</sup>The University of Hong Kong,&nbsp;
                      <sup>2</sup>Carnegie Mellon University,&nbsp;
                      <sup>3</sup>University of Sydney,&nbsp;
                      <sup>4</sup>RIKEN AIP,&nbsp;
                      <sup>5</sup>Shanghai Artificial Intelligence Laboratory,&nbsp;
                      <sup>6</sup>Shanghai Jiao Tong University,&nbsp;
                      <sup>7</sup>Hong Kong University of Science and Technology,&nbsp;
                      <sup>8</sup>Alibaba Group
                    </span>
                    <span class="eql-cntrb">
                      <small><br><sup>†</sup> Corresponding Authors</small>
                    </span>
                  </div>


                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- TODO: Update with your arXiv paper ID -->
                <!-- TODO: Update with your arXiv paper ID -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2507.16663" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>

                  <!-- TODO: Replace with your GitHub repository URL -->
                  <span class="link-block">
                    <a href="https://github.com/yujinhanml" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Coming Soon</span>
                  </a>
                </span>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser Image -->
<section class="section teaser">
  <div class="container is-max-desktop">
    <!-- 标题 -->
    <h2 class="title is-3 has-text-link has-text-centered" style="margin-bottom: 0.5rem;">
      Unified MLLMs Remain Non-unified
    </h2>
    <!-- <div class="title-underline has-text-link"></div> -->

    <!-- 灰色背景卡片 -->
    <div class="box" style="background-color: #f8f9ff; border-radius: 12px; padding: 2rem;">
      <div class="has-text-centered">
        <!-- 图片 -->
        <img src="static/images/self-contradictory.png" alt="MLLMs' internal gap"/>
        
        <!-- 图片说明 -->
        <h3 class="has-text-justified is-size-8" style="margin-top: .75rem;">
          <span class="has-text-weight-bold has-text-link">Illustration of MLLMs' internal gap.</span> We examine challenging cases involving implicit 
          physical principles using ChatGPT o3 and Gemini 2.5 Flash, and find: images produced 
          by generation branch are identified as incorrect by understanding branch, showing 
          non-unification.
        </h3>

        <!-- Key Insight 小节 -->
        <div class="has-text-left" style="margin-top: 1.5rem;">
          <h3 class="title is-4 has-text-link" style="margin-bottom: 0.25rem;">
            Key Insight
          </h3>
          <div class="content">
            <ul>
              <li>Unified MLLMs exhibit an internal gap: understanding typically outperforms generation.</li>
              <li>The gap mainly stems from weak generation rather than misunderstanding, motivating an internal gap-based self-improvement strategy.</li>
            </ul>
          </div>
        </div>


      </div>
    </div>
  </div>
</section>
<!-- End Teaser Image -->



<!-- Abstract Section -->
<section class="section">
  <div class="container is-max-desktop">
    <!-- 标题（蓝色 + 下划线） -->
    <h2 class="title is-3 has-text-link has-text-centered">
      Abstract
    </h2>
    <div class="title-underline has-text-link"></div>

    <!-- 灰色卡片（和 Teaser Image 一样宽） -->
    <div class="box" style="background-color: #f8f9ff; border-radius: 12px; padding: 2rem; margin-top: 1.5rem;">
      <div class="content has-text-justified">
        <p>
          Although unified MLLMs aim to unify generation and understanding, they are considered to exhibit an internal gap, with understanding outperforming generation. Through large-scale evaluation across multiple MLLMs and tasks, we confirm the widespread non-unification of MLLMs, and demonstrate that it indeed stems from weak generation rather than misunderstanding. This finding motivates us to propose a simple yet effective internal gap-based self-improvement framework, which mitigates internal gaps by leveraging stronger understanding to guide weaker generation without relying on any external signals. We validate this strategy through comprehensive experiments: scoring generations with understanding to construct image data for post-training (e.g., SFT and DPO) significantly improves generation while promoting unification. Furthermore, we empirically discover a co-improvement effect of such self-improvement, a phenomenon well known in pre-training but underexplored in post-training. Specifically, as generation improves, understanding becomes more effective at detecting false positives that were previously misclassified as prompt-aligned. To explain this effect, we extend learning dynamic theory to the MLLM setting, showing that the shared empirical neural tangent kernel between generation and understanding encourages aligned learning dynamics, thereby driving co-improvement. This interplay between generation and understanding further motivates a curriculum learning approach for stronger self-improvement: progressively enhanced understanding and generation revisit samples underutilized by pre-trained MLLMs, dynamically expanding post-training data and leading to improved performance and unification.
        </p>
      </div>
    </div>
  </div>
</section>
<!-- End Abstract Section -->



<!-- Image carousel (title changes with slide) -->
<section class="section">
  <div class="container is-max-desktop">
    <!-- 蓝色标题 -->
    <h2 id="carousel-title-1" class="title is-3 has-text-link has-text-centered">
      Phenomenon: Unified MLLMs remain non-unified with understanding outperforms generation
    </h2>
    <div class="title-underline has-text-link"></div>

    <!-- 灰色卡片 -->
    <div class="box" style="background-color: #f8f9ff; border-radius: 12px; padding: 2rem; margin-top: 1.5rem;">
      <div id="results-carousel-1" class="carousel results-carousel">
        
        <!-- Slide 1 -->
        <div class="item" data-title="Phenomenon: Pervasive Non-unification Mainly Stems from Weak Generation">
          <img src="static/images/nonunification_single.png" 
               alt="Verification of internal gaps" loading="lazy"/>
          <h2 class="subtitle has-text-justified" style="margin-top: 1rem;">
            <span class="has-text-weight-bold has-text-link">Verification of internal gaps.</span> (a) and (b) identify task difficulty as a confounder in measuring non-unification score (Non.): easy tasks may underestimate the gap, while hard tasks risk overestimation. Stratifying by task difficulty (Easy–Medium–Hard) yields a more reliable estimation. (c) Evaluation of six MLLMs across three difficulty levels shows unified MLLMs remain non-unified, with non-unification scores approaching 60%.
          </h2>
        </div>
        
        <!-- Slide 2 -->
        <div class="item" data-title="Internal gap mainly stems from weak generation instead of misunderstanding">
          <img src="static/images/reason.png" 
               alt="Weak generation explanation" loading="lazy"/>
          <h2 class="subtitle has-text-justified" style="margin-top: 1rem;">
            <span class="has-text-weight-bold has-text-link">Internal gap mainly stems from weak generation instead of misunderstanding.</span> Weak-generation (Qwen/Human-checked) above 50% (even 100%) indicate internal gap mainly stems from weak generation instead of misunderstanding.
          </h2>
        </div>

      </div> <!-- end results-carousel-1 -->
    </div> <!-- end box -->
  </div> <!-- end container -->
</section>


<!-- Teaser Image -->
<section class="section teaser">
  <div class="container is-max-desktop">

    <!-- 标题（蓝色） -->
    <h2 class="title is-3 has-text-link has-text-centered">
      Method: Internal Gap-based Self-Improvement
    </h2>
    <div class="title-underline has-text-link"></div>

    <!-- 卡片放在 container 下，宽度与其他一致 -->
    <div class="box" style="background-color:#f8f9ff; border-radius:12px; padding:1.5rem; margin-top:1.5rem;">

      <!-- 图片（仅缩小 70%，不影响卡片宽度） -->
      <img src="static/images/alg1.png" alt="MLLMs' internal gap"
           style="display:block; margin:1rem auto 0; max-width:70%; height:auto;">

      <!-- 说明文字 -->
      <h2 class="subtitle has-text-justified" style="font-size:1rem; margin-top:1rem;">
        <span class="has-text-weight-bold has-text-link">Self-improvement.</span> Scoring generations with stronger understanding to construct image data for post-training
        (e.g., SFT and DPO) on the generation branch.
      </h2>
    </div>
  </div>
</section>
<!-- End Teaser Image -->


<!-- Teaser Image -->
<section class="section teaser">
  <div class="container is-max-desktop">

    <!-- 标题（蓝色） -->
    <h2 class="title is-3 has-text-link has-text-centered">
      Experimental Finding 1: Self-improvement Effectively Improves Generation and Unification
    </h2>
    <div class="title-underline has-text-link"></div>

    <!-- 卡片放在 container 下，宽度与其他一致 -->
    <div class="box" style="background-color:#f8f9ff; border-radius:12px; padding:1.5rem; margin-top:1.5rem;">

      <img src="static/images/find1.png" alt="MLLMs' internal gap"
           alt="find 1" loading="lazy"/>

      <!-- 说明文字 -->
      <h2 class="subtitle has-text-justified" style="font-size:1rem; margin-top:1rem;">
        <span class="has-text-weight-bold has-text-link">
          Self-improvement enhances generation and unification, with gains up to 20% and 16% (1–non-unification score).
        </span>
        Furthermore, improvements correlate with the internal gap 
        (correlation coefficient \( \\rho_{\\Delta,\\text{Non.}} = 0.53 \)): 
        models and subtasks with larger gaps benefit more.
      </h2>

    </div>
  </div>
</section>
<!-- End Teaser Image -->

<!-- Experimental Finding 2 (Carousel) -->
<section class="section teaser">
  <div class="container is-max-desktop">

    <!-- 标题（蓝色） -->
    <h2 class="title is-3 has-text-link has-text-centered">
      Experimental Finding 2:  Co-improvement between Generation and Understanding
    </h2>
    <div class="title-underline has-text-link"></div>

    <!-- 浅蓝色卡片，内含轮播 -->
    <div class="box" style="background-color:#f8f9ff; border-radius:12px; padding:1.5rem; margin-top:1.5rem;">
      <div id="results-carousel-2" class="carousel results-carousel">

        <!-- Slide 1 -->
        <div class="item">
          <img src="static/images/find2.png" alt="Co-improvement overview" loading="lazy"/>
          <h3 class="subtitle has-text-justified" style="font-size:1rem; margin-top:1rem;">
            <span class="has-text-weight-bold has-text-link">Co-improvement Effect.</span>
            (a) shows an example where self-improved Janus-Pro generates prompt-aligned images and correctly scores the original as mismatched; (b) reports win rates mostly above 50%, indicating self-improved MLLMs judge prompt–image alignment more accurately than pre-trained ones.
            <br><br>
             <span class="has-text-weight-bold has-text-link">Win rate of understanding</span> is the proportion of cases where the self-improved MLLM disagrees with the pre-trained one but agrees with the stronger external judge, e.g., Qwen2.5-VL-72B-Instruct. For example, if the models disagree on three samples and the self-improved model matches Qwen on two, win rate is 2/3. 
          </h3>
        </div>

        <!-- Slide 2 -->
        <div class="item">
          <img src="static/images/find2-1.png" alt="Co-improvement example 1" loading="lazy"/>
          <h3 class="subtitle has-text-justified" style="font-size:1rem; margin-top:1rem;">
            <span class="has-text-weight-bold has-text-link">Examples of co-improvements of self‑improved Janus-Pro and Show-o under SFT.</span> We observe that, after self‑improvement, Show-o and Janus-Pro generate images that align prompts and accurately identify when images produced by the pre‑trained MLLM are misaligned with the prompts.
          </h3>
        </div>

        <!-- Slide 3 -->
        <div class="item">
          <img src="static/images/find2-2.png" alt="Co-improvement example 2" loading="lazy"/>
          <h3 class="subtitle has-text-justified" style="font-size:1rem; margin-top:1rem;">
            <span class="has-text-weight-bold has-text-link">Examples of co-improvements of self‑improved Janus-Pro and Show-o with DPO.</span>
             We observe that, after self‑improvement, Show-o and Janus-Pro generate images that align prompts and accurately identify when images produced by the pre‑trained MLLM are misaligned with the prompts.
          </h3>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Mechanism Section -->
<section class="section teaser">
  <div class="container is-max-desktop">

    <!-- 标题（蓝色） -->
    <h2 class="title is-3 has-text-link has-text-centered">
      Mechanism: Explaining the Co-improvement Effect from Learning Dynamics
    </h2>
    <div class="title-underline has-text-link"></div>

    <!-- 卡片包裹轮播 -->
    <div class="box" style="background-color:#f8f9ff; border-radius:12px; padding:1.5rem; margin-top:1.5rem;">
      <div id="results-carousel-2" class="carousel results-carousel">

        <!-- Slide 1 -->
        <div class="item" data-title="Proposition Evidence">
          <img src="static/images/proposition 1.png" alt="Learning dynamics proposition" loading="lazy"/>
          <h3 class="subtitle has-text-justified" style="font-size:1rem; margin-top:1rem;">
            <span class="has-text-weight-bold has-text-link">Theoretical Proposition.</span>
            Self-improvement enhances generation and unification, with gains up to 20% and 16% (1–non-unification score). 
            Improvements are explained by the alignment of empirical neural tangent kernel (eNTK) between two branches.
          </h3>
        </div>

        <!-- Slide 2 -->
        <div class="item" data-title="Empirical Evidence">
          <img src="static/images/evidence.png" alt="Empirical evidence of co-improvement" loading="lazy"/>
          <h3 class="subtitle has-text-justified" style="font-size:1rem; margin-top:1rem;">
            <span class="has-text-weight-bold has-text-link">Empirical Evidence from Self-improved Janus-Pro with SFT.</span>
            (a) Compared to random samples, $(\mathbf{y}_0,\mathbf{x}_0)$ in the false positive correction group 
            are more likely to be matched with highly similar post-training pairs $(\mathbf{y}_u,\mathbf{x}_u)$. 
            (b) Such high data similarity makes $\textcolor{lightblue}{\mathcal{K}^{\,t}_{k,r}(\mathcal{Y}_0,\mathcal{Y}_u)}$ 
            be the dominant term, thereby promoting aligned learning dynamics $\Delta G_t$ and $\Delta U_t$. 
            (c) With aligned dynamics, $\Delta G_t < 0$ implies $\Delta U_t < 0$: both the probability of 
            mis-generation $\pi_{\theta}(\mathbf{x}_0 \mid \mathbf{y}_0)$ and misjudging  
            $\pi_{\theta}(\mathbf{y}_0 \mid \mathbf{x}_0)$ are reduced, i.e., false positive correction and 
            co-improvement occur.
          </h3>
        </div>

      </div> <!-- end carousel -->
    </div> <!-- end box -->
  </div>
</section>
<!-- End Mechanism Section -->



<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@article{han2025turninginternalgapselfimprovement,
  title={Turning Internal Gap into Self-Improvement: Promoting the Generation-Understanding Unification in MLLMs},
  author={Yujin Han and Hao Chen and Andi Han and Zhiheng Wang and Xinyu Liu and Yingya Zhang and Shiwei Zhang and Difan Zou},
  year={2025},
  eprint={2507.16663},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2507.16663}, 
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

<script>
document.addEventListener("DOMContentLoaded", function () {
  // 1) 初始化轮播
  if (typeof bulmaCarousel !== 'undefined') {
    bulmaCarousel.attach('#results-carousel-1', {
      slidesToScroll: 1,
      slidesToShow: 1,
      infinite: false
    });
  }

  const root    = document.getElementById('results-carousel-1');
  const titleEl = document.getElementById('carousel-title-1');
  if (!root || !titleEl) return;

  function getActiveSlideEl() {
    return root.querySelector('.carousel-item.is-active') 
        || root.querySelector('.item.is-active') 
        || root.querySelector('.carousel-item') 
        || root.querySelector('.item');
  }

  function updateTitle() {
    const active = getActiveSlideEl();
    if (!active) return;

    // data-title 可能在当前 slide 元素上（推荐），也可能在其内部
    let elWithTitle = active;
    if (!elWithTitle.dataset || !elWithTitle.dataset.title) {
      elWithTitle = active.querySelector('[data-title]') || active;
    }
    const t = (elWithTitle.dataset && elWithTitle.dataset.title) ? elWithTitle.dataset.title : titleEl.textContent;
    titleEl.textContent = t;
  }

  // 初始更新（等一帧，让 bulma-carousel 完成 DOM 标记）
  requestAnimationFrame(updateTitle);

  // 监听 class 变化（切换时 is-active 会变）
  const mo = new MutationObserver(updateTitle);
  mo.observe(root, { attributes: true, subtree: true, attributeFilter: ['class'] });

  // 兼容：点击左右箭头 / 圆点后再更新一次
  root.addEventListener('click', (e) => {
    if (e.target.closest('.carousel-nav') || e.target.closest('.carousel-pagination')) {
      requestAnimationFrame(updateTitle);
    }
  });

  // 若拿得到实例，挂官方事件
  if (typeof bulmaCarousel !== 'undefined' && bulmaCarousel.instances && bulmaCarousel.instances.length) {
    const inst = bulmaCarousel.instances.find(i => i.element === root) || bulmaCarousel.instances[0];
    if (inst && typeof inst.on === 'function') {
      inst.on('after:show', updateTitle);
      inst.on('after:slide', updateTitle);
      // 某些版本还有 init 事件
      inst.on('after:init', updateTitle);
    }
  }
});
</script>




  </body>
  </html>
